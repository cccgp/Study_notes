参考代码：https://github.com/jacobgil/pytorch-tensor-decompositions

1. AlexNet-20%的近似参数，当读取分解后的模型即可打印模型得到信息。，


2. AlexNet-10%的近似参数
AlexNet(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 30, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2), bias=False)
      (2): Conv2d(30, 64, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Sequential(
      (0): Conv2d(64, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(50, 71, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)
      (2): Conv2d(71, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): Conv2d(192, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(75, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(80, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (7): ReLU(inplace=True)
    (8): Sequential(
      (0): Conv2d(384, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(66, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (9): ReLU(inplace=True)
    (10): Sequential(
      (0): Conv2d(256, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(66, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(70, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=45, bias=True)
  )
)

3. VGG-20%的近似参数，当读取分解后的模型即可打印模型得到信息。
VGG(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(64, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(43, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(58, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Sequential(
      (0): Conv2d(128, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(66, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Sequential(
      (0): Conv2d(256, 86, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(86, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace=True)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Sequential(
      (0): Conv2d(256, 114, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(114, 143, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(143, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Sequential(
      (0): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(135, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(132, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (22): Sequential(
      (0): Conv2d(512, 161, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(161, 141, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(141, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): ReLU(inplace=True)
    (25): Sequential(
      (0): Conv2d(512, 155, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(155, 161, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(161, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (27): ReLU(inplace=True)
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=45, bias=True)
  )
)

4. VGG-10%
VGG(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(12, 64, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Conv2d(64, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(43, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(59, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Sequential(
      (0): Conv2d(128, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(66, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Sequential(
      (0): Conv2d(256, 87, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(87, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace=True)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Sequential(
      (0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(113, 143, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(143, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Sequential(
      (0): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(135, 133, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(133, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (22): Sequential(
      (0): Conv2d(512, 161, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(161, 143, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(143, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): ReLU(inplace=True)
    (25): Sequential(
      (0): Conv2d(512, 156, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(156, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): Conv2d(158, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (27): ReLU(inplace=True)
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=45, bias=True)
  )
)
