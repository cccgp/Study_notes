# 1. 配置环境
1. 安装Anaconda
   - 使用```$conda -V```检查
2. 创建虚拟环境
   - ```$conda create -n your_env_name python=x.x```
   - 键入命令后，在```## Package Plan ##```部分会提示虚拟环境所在位置
3. 激活虚拟环境
   - ```$source activate your_env_name```
4. 退出虚拟环境
   - ```$source deactivate your_env_name```
5. 安装pytorch
   - 检查cuda版本：`$nvidia-smi`，结果中的`CUDA Version`即cuda版本
   - https://pytorch.org/ ，按照网站中的命令安装即可
   - 验证pytorch版本
     - ```$python```
     -  ```
        import torch
        print(torch.__version__)
        print(torch.version.cuda)
        print(torch.backends.cudnn.version())
        ```
6. 自动登陆ssh和sftp
   - 由于每次登陆ssh后还需要做一些工作才方便使用，于是配置了shell脚本，在iTerm2启动之前执行，点击图标之后，即可自动做完所有初始化工作，直接利于使用ssh和sftp。        
# 2. Network + NWPU-RESISC45
微调指南：
https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html
## 2.1 AlexNet 
   - src/alextNet_20%.py
   - 参数设置：切分比例:20%，Epoch:15,batch size = 128,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.806865
   - src/alextNet_10%.py
   - 参数设置：切分比例:10%，Epoch:15,batch size = 128,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.762822

## 2.2 VGG-11
   - src/vggNet_20%.py
   - 参数设置：切分比例:20%，Epoch:35,batch size = 50,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.894683
   - src/vggNet_10%.py
   - 参数设置：切分比例:10%，Epoch:15,batch size = 50,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.853757

## 2.3 squeezenet
   - src/squeezenet_20%.py
   - 参数设置：切分比例:20%，Epoch:15,batch size = 120,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.794405
   - src/squeezenet_10%.py
   - 参数设置：切分比例:10%，Epoch:15,batch size = 120,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.747619

## 2.4 resnet
   - src/resNet_20%.py
   - 参数设置：切分比例:20%，Epoch:100,batch size = 120,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.900119
   - src/resNet_10%.py
   - 参数设置：切分比例:10%，Epoch:100,batch size = 120,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.864092

# 3. Model compression
指定GPU可见，方便指定GPU训练
- $CUDA_VISIBLE_DEVICES=1 python my_script.py

- 使用sequential搭建模型，分为features及classifier两个部分，可以使用model.classifier[1]引用特定层

- 杀死进程，释放显存，例如运行包含train_imagenet文件的进程，ps -ef | grep train_imagenet | grep -v grep | cut -c 9-15 | xargs kill -9

  
## 3.1 权值压缩 + NWPU-RESISC45
- 剪枝指南：https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#global-pruning
### 3.1.1 AlexNet
   - pruning/pruning_alexNet_10%.py
   - 参数设置：切分比例:10%，Epoch:100,batch size = 128,learning rate = 0.001,momentum = 0.9 
   - 实验结果：0.773157
   - 压缩率：0.85
   - pruning/pruning_alexNet_20%.py
   - 参数设置：切分比例:20%，Epoch:50,batch size = 128,learning rate = 0.001,momentum = 0.9 
   - 实验结果：0.791984
   - 压缩率：0.85 
### 3.1.2 VGG
   - pruning/pruning_vggNet_10%.py
   - 参数设置：切分比例:10%，Epoch:100,batch size = 50,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.860176
   - 压缩率：0.85
   - pruning/pruning_vggNet_20%.py
   - 参数设置：切分比例:20%，Epoch:100,batch size = 50,learning rate = 0.001,momentum = 0.9
   - 实验结果：0.899563
   - 压缩率：0.85 

### 3.1.3 方法说明
- 实验中使用的TORCH.NN.UTILS.PRUNE.GLOBAL_UNSTRUCTURED
  https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html
- 具体使用的方法prune.L1Unstructured
  https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html
- ```
    prune.global_unstructured(
         parameters_to_prune,
         pruning_method=prune.L1Unstructured,
         amount=0.85
    )
## 3.2 局部压缩 + NWPU-RESISC45

## 3.3. 全局压缩 + NWPU-RESISC45

